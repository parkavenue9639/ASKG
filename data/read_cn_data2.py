import torch
from torch.utils.data import Dataset
from PIL import Image

import os
import pickle as pkl
import numpy as np


class CHXrayDataSet2(Dataset):
    def __init__(self, opt, split, transform=None):
        self.transform = transform

        self.data_dir = opt.data_dir
        # TODO
        self.pkl_dir = '../data/processed_chxray_precise_tag/'
        self.img_dir = os.path.join(self.data_dir, 'NLMCXR_png')

        self.num_medterm = opt.num_medterm  # æŒ‡å®šåŒ»å­¦æœ¯è¯­çš„æ•°é‡

        with open(os.path.join(self.pkl_dir, 'align2.' + split + '.pkl'), 'rb') as f:
            self.findings = pkl.load(f)  # å½±åƒå¯¹åº”çš„æ–‡æœ¬æè¿°
            self.findings_labels = pkl.load(f)  # æ–‡æœ¬æè¿°çš„æ ‡ç­¾
            self.image = pkl.load(f)  # å½±åƒæ–‡ä»¶å
            self.medterms = pkl.load(f)  # å½±åƒå¯¹åº”çš„åŒ»å­¦æœ¯è¯­  length:1470

        f.close()

        with open(os.path.join(self.pkl_dir, 'word2idw.pkl'), 'rb') as f:
            self.word2idw = pkl.load(f)  # å•è¯åˆ°idçš„æ˜ å°„ï¼Œç”¨äºæ–‡æœ¬å¤„ç†
            # print(len(self.word2idw))  1779
            # print(self.word2idw)  {'word', id}
        f.close()

        # ä¸­æ–‡pklæ–‡ä»¶ï¼Œåˆ›å»ºåå‘è¯å…¸ï¼Œç”¨äºå°†idè½¬æ¢ä¸ºå•è¯
        self.idw2word = {v: k for k, v in self.word2idw.items()}

        self.ids = list(self.image.keys())  # è·å–æ‰€æœ‰çš„å½±åƒid
        self.vocab_size = len(self.word2idw)  # è¯æ±‡è¡¨å¤§å°

        print('CHXrayDataSet2 {} init completeï¼Œ len : {}'.format(split, len(self.image)))
        self.checkdata()

    def __getitem__(self, index):
        ix = self.ids[index]  # è·å–å½±åƒid
        image_id = self.image[ix]  # è·å–å½±åƒæ–‡ä»¶å
        image_name = os.path.join(self.img_dir, image_id)  # æ‹¼æ¥å®Œæ•´è·¯å¾„
        img = Image.open(image_name).convert('RGB')  # æ‰“å¼€å›¾åƒï¼Œè½¬æ¢ä¸ºRGBï¼ˆé¿å…PILå¤„ç†ç°åº¦å›¾æ—¶å‡ºé”™ï¼‰
        if self.transform is not None:
            img = self.transform(img)  # æ•°æ®å¢å¼ºï¼Œå¯¹å›¾åƒè¿›è¡Œå˜æ¢

        #print(img.size(), image_id)
        medterm_labels = np.zeros(229)
        # medterm_labels = np.zeros(self.num_medterm)
        medterms = self.medterms[ix]
        for medterm in medterms:
            # medterm_labels[medterm] = 1
            if medterm < self.num_medterm:
                medterm_labels[medterm] = 1
        # print("medterm_labels shape{}".format(medterm_labels.shape))  # (50176,)

        findings = self.findings[ix]
        findings_labels = self.findings_labels[ix]
        findings = np.array(findings)
        findings_labels = np.array(findings_labels)

        findings = torch.from_numpy(findings).long()
        findings_labels = torch.from_numpy(findings_labels).long()


        return ix, image_id, img, findings, findings_labels, torch.FloatTensor(medterm_labels)

    def __len__(self):
        return len(self.ids)

    def checkdata(self):
        """æ‰“å°æ•°æ®é›†ç»“æ„ï¼Œå¹¶è§£ç  findings_labels ä¸ medterms çš„å‰å‡ ä¸ªæ ·æœ¬"""

        def decode_sequence(seq):
            """æ ¹æ®æ¨¡å‹è§£ç è§„åˆ™ï¼Œå°†ä¸€ä¸ª token ID åºåˆ—è§£ç æˆå­—ç¬¦ä¸²"""
            words = []
            for token_id in seq:
                if token_id < 0:
                    continue
                token = self.idw2word.get(token_id, '<UNK>')
                if token in ['<BOS>', '<BLANK>', '<UNK>']:
                    continue
                if token == '<EOS>':
                    break
                words.append(token)
            return ' '.join(words)

        data_attrs = {
            'findings': self.findings,
            'findings_labels': self.findings_labels,
            'image': self.image,
            'medterms': self.medterms,
            'word2idw': self.word2idw,
            'idw2word': self.idw2word,
            'ids': self.ids
        }

        for attr_name, attr_value in data_attrs.items():
            print(f"\nğŸ§© Checking {attr_name}:")

            if isinstance(attr_value, dict):
                sample_keys = list(attr_value.keys())[:5]
                for key in sample_keys:
                    val = attr_value[key]
                    val_len = len(val) if hasattr(val, '__len__') else 'N/A'
                    if attr_name in ['findings_labels', 'medterms']:
                        decoded = decode_sequence(val)
                        print(f"  Key: {key} | Type: {type(val)} | Length: {val_len} | Decoded: {decoded}")
                    else:
                        print(f"  Key: {key} | Type: {type(val)} | Length: {val_len} | Value: {val}")

            elif isinstance(attr_value, list):
                for i, elem in enumerate(attr_value[:3]):
                    val_len = len(elem) if hasattr(elem, '__len__') else 'N/A'
                    if attr_name in ['findings_labels', 'medterms']:
                        decoded = decode_sequence(elem)
                        print(f"  Index {i} | Type: {type(elem)} | Length: {val_len} | Decoded: {decoded}")
                    else:
                        print(f"  Index {i} | Type: {type(elem)} | Length: {val_len} | Value: {elem}")

            else:
                val_len = len(attr_value) if hasattr(attr_value, '__len__') else 'N/A'
                print(f"  Type: {type(attr_value)} | Length: {val_len} | Sample Value: {attr_value}")